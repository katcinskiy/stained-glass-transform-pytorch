{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "015942f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d72e2b4",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2bbd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.amp import autocast, GradScaler\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import datasets\n",
    "import neptune\n",
    "from loss_new import SGTLoss\n",
    "\n",
    "import json\n",
    "\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from metrics import cos_metric, topk_intersection_metric, reconstruction_rank_metric\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from dataset import SGTDataset\n",
    "\n",
    "from sgt_model import SGTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773b83ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "llm = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\", device_map=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4009646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"ai2_arc\", \"ARC-Challenge\")['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b72a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([151936, 1536])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model.embed_tokens.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24aa1e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(151936, 1536)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model.embed_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb0c01",
   "metadata": {},
   "source": [
    "### Test metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add2d891",
   "metadata": {},
   "source": [
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbe649c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (9) must match the size of tensor b (151936) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtest_metrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m test_reconstruction_ranks_zero\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# test_reconstruction_ranks_zero(\"euclid\")\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mtest_reconstruction_ranks_zero\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcosine\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ml/research/llms/obfuscation/stained-glass-transform-pytorch/train/test_metrics.py:23\u001b[39m, in \u001b[36mtest_reconstruction_ranks_zero\u001b[39m\u001b[34m(similarity)\u001b[39m\n\u001b[32m     20\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33mThe quick brown fox jumps over the lazy dog\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     21\u001b[39m tokenized = tokenizer(text, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).to(device)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m clean_embeddings = llm.model.embed_tokens(tokenized[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     25\u001b[39m ranks = _reconstruction_ranks(\n\u001b[32m     26\u001b[39m     clean_embeddings,\n\u001b[32m     27\u001b[39m     llm.model.embed_tokens.weight.to(device),\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     similarity=similarity,\n\u001b[32m     31\u001b[39m )\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# check size\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ml/research/llms/obfuscation/stained-glass-transform-pytorch/train/metrics.py:33\u001b[39m, in \u001b[36m_reconstruction_ranks\u001b[39m\u001b[34m(obf_embeds, vocab_embeds, input_ids, mask, similarity)\u001b[39m\n\u001b[32m     31\u001b[39m     distances = torch.cdist(obf_flat, vocab_embeds)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m similarity == \u001b[33m\"\u001b[39m\u001b[33mcosine\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     distances = \u001b[32m1\u001b[39m - torch.cosine_similarity(obf_flat, vocab_embeds.unsqueeze(\u001b[32m0\u001b[39m), dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown similarity type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimilarity\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (9) must match the size of tensor b (151936) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "from test_metrics import test_reconstruction_ranks_zero\n",
    "\n",
    "\n",
    "# test_reconstruction_ranks_zero(\"euclid\")\n",
    "test_reconstruction_ranks_zero(\"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc222ae6",
   "metadata": {},
   "source": [
    "nn_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "680c0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_metrics import test_nn_fr_zero\n",
    "\n",
    "\n",
    "test_nn_fr_zero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "829125de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from test_metrics import test_nn_fr_one_embed_wrong\n",
    "\n",
    "\n",
    "test_nn_fr_one_embed_wrong()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db60d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_metrics import test_nn_fr_one_embed_wrong_with_attention_mask\n",
    "\n",
    "\n",
    "test_nn_fr_one_embed_wrong_with_attention_mask()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e03cd8",
   "metadata": {},
   "source": [
    "mrp_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "509290e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_metrics import test_mrp_fr_zero\n",
    "\n",
    "\n",
    "test_mrp_fr_zero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4025bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_metrics import test_mrp_fr_one_embed_wrong\n",
    "\n",
    "\n",
    "test_mrp_fr_one_embed_wrong()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fe12125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_metrics import test_mrp_fr_with_attention_mask\n",
    "\n",
    "\n",
    "test_mrp_fr_with_attention_mask()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9246d4e",
   "metadata": {},
   "source": [
    "### DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72b4985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from metrics import nn_fr_metric as nn_fr\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "llm = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cc7a40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   785,   3974,  13876,  38835,  34208,    916,    279,  15678,   5562],\n",
       "        [ 32847,  23694, 151645, 151645, 151645, 151645, 151645, 151645, 151645]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\"The quick brown fox jumps over the lazy dog\", \"Happy pig\"]\n",
    "tokenized = tokenizer(texts, return_tensors='pt', padding=True).to(device)\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01b0ab3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9746, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(38.5595, grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "tokenized = tokenizer(text, return_tensors='pt').to(device)\n",
    "\n",
    "clean_embeddings = llm.model.embed_tokens(tokenized['input_ids'])\n",
    "\n",
    "print(clean_embeddings[0][1].norm())\n",
    "\n",
    "clean_embeddings[0][1] += torch.randn_like(clean_embeddings[0][1])\n",
    "\n",
    "print(clean_embeddings[0][1].norm())\n",
    "\n",
    "# actual = nn_fr(clean_embeddings, llm.model.embed_tokens, tokenized['input_ids'], tokenized['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277313ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(100.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f97afe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
