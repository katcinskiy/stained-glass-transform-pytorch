{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1dfb612",
   "metadata": {},
   "source": [
    "# Model inversion attack against SGT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df13db5f",
   "metadata": {},
   "source": [
    "This code explores how a model inversion attack might work against the SGT. My main idea was to test the following: even if SGT corrupts the input embeddings, the fact that the model still functions means we can potentially exploit its prior knowledge to reconstruct the original input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f69e1f",
   "metadata": {},
   "source": [
    "Code of training inverison model is available at https://github.com/katcinskiy/model-inversion-attack\n",
    "\n",
    "Pretrain for inverion model: https://drive.google.com/drive/folders/10P259HD9siA4foxBeN8c_pIdKeKmWM8R?usp=share_link\n",
    "\n",
    "Pretrain for SGT: https://drive.google.com/drive/folders/1j-h2Xz7KWn1xgxJFYqoAt0kMZz-ogRry?usp=share_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f53d9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/research/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02d4e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16bc206",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_NAME = \"Qwen/Qwen2.5-1.5B\"\n",
    "INVERSE_MODEL_NAME = \"facebook/bart-base\"\n",
    "\n",
    "llm_tokenizer = AutoTokenizer.from_pretrained(LLM_NAME)\n",
    "llm_tokenizer.pad_token = llm_tokenizer.eos_token\n",
    "base_llm = AutoModelForCausalLM.from_pretrained(LLM_NAME, device_map=device)\n",
    "\n",
    "inv_tokenizer = AutoTokenizer.from_pretrained(INVERSE_MODEL_NAME)\n",
    "inv_base_model = BartForConditionalGeneration.from_pretrained(INVERSE_MODEL_NAME, device_map=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b86da",
   "metadata": {},
   "source": [
    "## Loading pretrained SGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0620014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_init_weight is None - skipping mu_head.weight initialization\n",
      "mu_init_bias is None - skipping mu_head.bias initialization\n",
      "logvar_init_weight is None - skipping logvar_head.weight initialization\n",
      "logvar_init_bias is None - skipping logvar_head.bias initialization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sgt_model import SGTModel\n",
    "\n",
    "sgt = SGTModel(1536, 8, 2, 1, None, None, None, None).to(device)\n",
    "\n",
    "sgt.load_state_dict(torch.load('pretrain_sgt_cos_only.pt'))\n",
    "# sgt.load_state_dict(torch.load('pretrain_sgt_cos_and_mselogvar.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "435a9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM(torch.nn.Module):\n",
    "    def __init__(self, sgt, base_llm):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sgt = sgt\n",
    "        self.base_llm = base_llm\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, **kwargs):\n",
    "        embeds = self.base_llm.model.embed_tokens(input_ids)\n",
    "        embeds, _, _ = self.sgt.sample(embeds, attention_mask=attention_mask)\n",
    "\n",
    "        return self.base_llm(inputs_embeds=embeds, attention_mask=attention_mask, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "524ed878",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(sgt, base_llm).eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a791cc",
   "metadata": {},
   "source": [
    "## Loading pretrained inverse model for different layers and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9058420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-08-30 09:23:21--  https://raw.githubusercontent.com/katcinskiy/model-inversion-attack/master/models.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8001::154, 2606:50c0:8002::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8001::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3677 (3,6K) [text/plain]\n",
      "Saving to: ‘models.py.1’\n",
      "\n",
      "models.py.1         100%[===================>]   3,59K  --.-KB/s    in 0,01s   \n",
      "\n",
      "2025-08-30 09:23:21 (363 KB/s) - ‘models.py.1’ saved [3677/3677]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/katcinskiy/model-inversion-attack/master/models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185e115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_model_path = [\n",
    "    'MIA_pretrain_1_layer.bin',\n",
    "    'MIA_pretrain_2_layer.bin',\n",
    "    'MIA_pretrain_3_layer.bin',\n",
    "    'MIA_pretrain_4_layer.bin'\n",
    "]\n",
    "\n",
    "texts = [\n",
    "    \"Alexander Green's checking account shows a recent deposit of $4,250 on September 15, 2025.\",\n",
    "    \"Jessica Rivera lives at 29 Oakwood Lane, Riverton, and her contact number is (555) 234-8790.\",\n",
    "    \"Marcus Lee registered his driver's license DL9823475 in the state of California.\",\n",
    "    \"Emily Thompson’s email is emily.t92@example.net, which she also uses for online banking.\",\n",
    "    \"Benjamin Harris has a medical record ID MRN-45721-B, issued by St. Mary’s Hospital.\"\n",
    "]\n",
    "\n",
    "LAYERS = len(inv_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c8cc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,538,944 || all params: 142,959,360 || trainable%: 2.4755\n",
      "\n",
      "------- Reversed texts for layer 1 -------\n",
      "Alexander Green's checking account shows a recent deposit of $4,250 on September 15, 2000.\n",
      "Jessica Rivera lives at 2900 Oakwood Lane, Renton, and her contact number is (585) 233-7684.\n",
      "Marcus Lee registered his driver's license DL949704 in the state of California.\n",
      "Emily Thompson's email is emilyt902 logo.net, which she also uses for online banking.\n",
      "Benjamin Harris has a medical record ID MRN-455772-B, issued by St. Mary's Hospital.\n",
      "\n",
      "trainable params: 3,538,944 || all params: 142,959,360 || trainable%: 2.4755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/research/.venv/lib/python3.13/site-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/home/alex/research/.venv/lib/python3.13/site-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------- Reversed texts for layer 2 -------\n",
      "Alexander Green's checking account shows a recent deposit of \\$4,2,3 on September 17, 2017.\n",
      "Maria Rodriguez lives at 29 Oakwood Lane, Renton, and her contact number is (55) 2-8-8.\n",
      "Lee Lee registered his driver's license DL9 in the state of California.\n",
      "Emily Whitman's email is emilyt72 email, which she also uses for online banking.\n",
      "Benjamin Harris has a medical record ID MRN-4447-B, issued by St. Mary's Hospital.\n",
      "\n",
      "trainable params: 3,538,944 || all params: 142,959,360 || trainable%: 2.4755\n",
      "\n",
      "------- Reversed texts for layer 3 -------\n",
      "Australia's checking account shows a recent deposit of $4,2,250 on September 25.\n",
      "Maria Rodriguez lives at 29 Oakwood Lane, her contact number is (55) Oakwood, and her contact telephone is Rivona.\n",
      "Manuel registered his driver's license DL964\n",
      "Emily's account is emily.t, which she also uses for online banking\n",
      "Benjamin Harris has a medical record ID MRN-423, issued by St. Mary's Hospital.\n",
      "\n",
      "trainable params: 3,538,944 || all params: 142,959,360 || trainable%: 2.4755\n",
      "\n",
      "------- Reversed texts for layer 4 -------\n",
      "Green Green's checking account shows a recent deposit of 4,2,25.\n",
      "Maria Rodriguez lives at 29 Oakwood Lane, her contact number is (5) and her contact is\n",
      "James Lee registers his driver's license DL982 in California\n",
      "Edward Stevensons email is emilyt password, which she sews online banking net.\n",
      "Benjamin Harris has a medical record HRN-456, issued by St. Mary's Hospital.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models import InversionModel\n",
    "\n",
    "for layer in range(LAYERS):\n",
    "\n",
    "    inv_model = InversionModel(inv_base_model, inv_tokenizer, 1536).eval().to(device)\n",
    "    inv_model.load_state_dict(torch.load(inv_model_path[layer]))\n",
    "\n",
    "    all_tokenized = [llm_tokenizer(text, return_tensors='pt') for text in texts]\n",
    "\n",
    "    outputs = [llm(**tokenized.to(device)) for tokenized in all_tokenized]\n",
    "\n",
    "    generated_texts = [inv_model.generate_text(\n",
    "        encoder_embeds=outputs[i].hidden_states[layer + 1], \n",
    "        encoder_attention_mask=all_tokenized[i]['attention_mask'],\n",
    "        max_length=42,\n",
    "        do_sample=True,\n",
    "        temperature=1.0\n",
    "    )[0] for i in range(len(texts))]\n",
    "\n",
    "    print()\n",
    "    print(f\"------- Reversed texts for layer {layer + 1} -------\")\n",
    "\n",
    "    for text in generated_texts:\n",
    "        print(text)\n",
    "\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
